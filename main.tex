\documentclass{beamer}
%
% Choose how your presentation looks.
%
% For more themes, color themes and font themes, see:
% http://deic.uab.es/~iblanes/beamer_gallery/index_by_theme.html
%
\mode<presentation>
{
  \usetheme{default}      % or try Darmstadt, Madrid, Warsaw, ...
  \usecolortheme{default} % or try albatross, beaver, crane, ...
  \usefonttheme{default}  % or try serif, structurebold, ...
  \setbeamertemplate{navigation symbols}{}
  \setbeamertemplate{caption}[numbered]
  \setbeamertemplate{footline}[frame number]
} 

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}

\title{Functional ntuple filters for ROOT}
\author{Jim Pivarski}
% \institute{Where You're From}
% \date{Date of Presentation}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}[fragile]{Motivation}

\begin{block}{}
The process of cutting and transforming ntuples, putting results in plots, is the essence of exploratory data analysis. It's the primary way physicists interact with data and learn things from it.
\end{block}

\begin{block}{}
ROOT has a mini-language for cuts and transformations:
{\scriptsize \begin{verbatim}
    ttree->Draw("fNtrack / fNvertex", "fIsValid && fFlag == 1")
\end{verbatim}}
Like an SQL-select and SQL-where (no SQL-groupby).
\end{block}

\begin{itemize}
\item Good for quick plots on flat ntuples (very important!)
\item Limited ability to transform ntuples with array or record structure, sometimes ambiguous syntax
\item Users can go beyond this by writing explicit for-loops over ntuple contents, but at a cost:
\begin{itemize}
\item Explicit, imperative programs can't be easily parallelized
\item Pointer issues and reusing data (for speed) can lead to major bugs from uninitialized data and subtle bugs from stale data
\end{itemize}
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Motivation}
C++11 introduced a syntax for inline functions, which would make a functional style convenient. For instance, the mini-language could be replaced by:
{\scriptsize \begin{verbatim}
    ntuple->Draw([](Event _) { return _.fNtrack / _.fNvertex; },
                 [](Event _) { return _.fIsValid && _.fFlag == 1; });
\end{verbatim}}

\vfill
Functional pipelines form the basis of data manipulation in R, NumPy, Hadoop, Spark, SQL, Lisp, and others.

\vfill
The basic style is (Spark example):
{\scriptsize \begin{verbatim}
    val output = input.filter(x => x.fIsValid && x.fFlag == 1)
                      .map(x => x.fNtrack / x.fNvertex)    // set up chain
    output.take(10)                                        // get 10 outputs
\end{verbatim}}
\begin{itemize}
\item No explicit index, only dummy variables
\item Small, memorable collection of functors ({\tt map}, {\tt reduce}, etc.)
\item Parallelization is handled by back-end code
\item Data source may have unknown or infinite size
\end{itemize}
\end{frame}

\begin{frame}[fragile]{Exploratory examples}

\begin{itemize}
\item Looked at {\tt dt\_DrawTest.C}, {\tt dt\_MakeRef.C}, and {\tt stress.cxx} for examples of the kinds of operations to perform.
\item Set up a test in Python:
\begin{itemize}
\item Implemented some common functors with a fluent style: {\tt collection.functor(userFunction)...}
\item Converted {\tt Event.root} from ROOT testing suite into Avro for Pythonic access.
\item Using PyROOT to verify that ROOT syntax and functional chains produce identical histograms.
\end{itemize}
\end{itemize}

\begin{block}{Example:}
\vspace{-0.5\baselineskip}
{\scriptsize \begin{verbatim}
    ttree.Draw("fNtrack >> hNtrack")
    assert Data.source().map(lambda _: _.fNtrack).matches("hNtrack")
\end{verbatim}}

\vspace{-0.5\baselineskip}
where {\tt Data.source()} produces a lazy input stream, {\tt matches("hNtrack")} evaluates the stream, fills a histogram with the same range as {\tt hNtrack}, and verifies identical contents.
\end{block}
\end{frame}

\begin{frame}[fragile]{Examples}
\begin{block}{Filtering}
\vspace{-0.5\baselineskip}
{\scriptsize \begin{verbatim}
    ttree.Draw("fNtrack", "fFlag == 1")
    Data.source().filter(lambda _: _.fFlag == 1).map(lambda _: _.fNtrack)
\end{verbatim}}

Note: filter must go before the transformation!

\vspace{0.2 cm}
Type constants can ensure this order:
\begin{itemize}
\item {\tt filter} takes a {\tt function<Event -> bool>} and returns {\tt collection<Event>}
\item {\tt map} takes a {\tt function<Event -> <T> >} and returns {\tt collection<T>} (in this case, {\tt collection<int>})
\end{itemize}

\vspace{0.2 cm}
Idle question\ldots\ would C++ type specification and templating make this unreadable?
\end{block}
\end{frame}

\begin{frame}[fragile]{Examples}
\begin{block}{Weighting?}
Filters in functional chains are always boolean, but in HEP it can be very important to weight events by a floating point number.

{\scriptsize \begin{verbatim}
    ttree.Draw("fNtrack", "(fTemperature - 20.5)**2")
\end{verbatim}}

Perhaps express this as a stream of value-weight pairs? (Must be explicitly passed on through pipeline.)

{\scriptsize \begin{verbatim}
    Data.source().map(lambda _: (_.fNtrack, (_.fTemperature - 20.5)**2))
\end{verbatim}}

Perhaps a special {\tt weight} functor modifies the {\tt collection<T>} itself? Every functor would have to know about weights and pass them on automatically.

{\scriptsize \begin{verbatim}
    Data.source().weight(lambda _: (_.fTemperature - 20.5)**2)
                 .map(lambda _: _.fNtrack)
\end{verbatim}}
\end{block}
\end{frame}

\begin{frame}[fragile]{Examples}
\begin{block}{Record structure}
\vspace{-0.5\baselineskip}
{\scriptsize \begin{verbatim}
    ttree.Draw("fEvtHdr.fEvtNum + fTemperature * 6")
    Data.source().map(lambda _: _.fEvtHdr.fEvtNum + _.fTemperature * 6)
\end{verbatim}}
\vspace{-0.5\baselineskip}
\end{block}

\begin{block}{Fixed-length subcollections}
\vspace{-0.5\baselineskip}
{\scriptsize \begin{verbatim}
    ttree.Draw("fMatrix")
    Data.source().map(lambda _: _.fMatrix).flatten().flatten()
    Data.source().map(lambda _: _.fMatrix[:][:]).flatten().flatten()
    Data.source().map(lambda _: _.fMatrix[:,:]).flatten().flatten()

    ttree.Draw("fMatrix[][0]")
    Data.source().map(lambda _: _.fMatrix[:,0]).flatten()
    Data.source().flatMap(lambda _: _.fMatrix[:,0])

    ttree.Draw("fMatrix[1][]")
    Data.source().map(lambda _: _.fMatrix[1,:]).flatten()
    Data.source().flatMap(lambda _: _.fMatrix[1,:])

    ttree.Draw("fMatrix[2][2]")
    Data.source().map(lambda _: _.fMatrix[2,2])
\end{verbatim}}
\vspace{-0.5\baselineskip}
Note: {\tt flatMap} is equivalent to {\tt map} followed by {\tt flatten}, but it provides an optimization hint.
\end{block}
\end{frame}

\begin{frame}[fragile]{Examples}
\begin{block}{Variable-length subcollections}
\vspace{-0.5\baselineskip}
{\scriptsize \begin{verbatim}
    ttree.Draw("fClosestDistance")
    Data.source().map(lambda _: _.fClosestDistance).flatten()
    Data.source().flatMap(lambda _: _.fClosestDistance)

    ttree.Draw("fTemperature - 20 * Alt$(fClosestDistance[9], 0)")
    Data.source().filterMap(lambda _: _.fTemperature - 20 *
                                      _.fClosestDistance.getOrElse(9, 0.0))

    ttree.Draw("fClosestDistance[2]")
    Data.source().filterMap(lambda _: _.fClosestDistance.getOrElse(2, None))
    Data.source().map(lambda _: _.fClosestDistance).flatMapGet(2)
\end{verbatim}}
\vspace{-0.5\baselineskip}
Note: {\tt filterMap} drops {\tt None} (or {\tt nullptr}) results, similar to {\tt flatMap} but thinking of a nullable value as a collection of zero or one elements.

\vspace{0.5\baselineskip}
{\tt flatMapGet} maps a {\tt get} operation across subcollections, keeping only those for which the specified index exists. Perhaps a better solution than {\tt filterMap}, though less general.
\end{block}
\end{frame}

\begin{frame}[fragile]{Examples}
\begin{block}{Subcollections of records}
\vspace{-0.5\baselineskip}
{\scriptsize \begin{verbatim}
    ttree.Draw("fTracks.fPx")

    # flat chain
    Data.source().flatMap(lambda event: event.fTracks)
                 .map(lambda track: track.fPx)

    # nested chain
    Data.source().flatMap(lambda event:
                              event.fTracks.map(lambda track:
                                                    track.fPx))
\end{verbatim}}
\vspace{-0.5\baselineskip}
\end{block}

\begin{block}{Subcollections of records with filtering}
\vspace{-0.5\baselineskip}
{\scriptsize \begin{verbatim}
    ttree.Draw("fNpoint", "fPx < 0)              # cut on track feature
    Data.source().flatMap(lambda _: _.fTracks)
                 .filter(lambda _: _.fPx < 0)    # filter tracks
                 .map(lambda _: _.fNpoint)

    ttree.Draw("fNpoint", "fIsValid")            # cut on event feature
    Data.source().filter(lambda _: _.fIsValid)   # filter events
                 .flatMap(lambda _: _.fTracks)
                 .map(lambda _: _.fNpoint)
\end{verbatim}}
\vspace{-0.5\baselineskip}
\end{block}

\end{frame}





%% ttree.Draw("fTracks.fVertex[0]")
%% # you might think it's this:
%% # Data.source().flatMap(lambda event: event.fTracks.map(lambda track: track.fVertex[0]))
%% # but no, it's actually this:
%% Data.source().flatMap(lambda event: event.fTracks[0].fVertex)

%% ttree.Draw("fTracks[0].fVertex")
%% # now you might think it's reversed:
%% # Data.source(100).flatMap(lambda event: event.fTracks.map(lambda track: track.fVertex[0]))
%% # but no, it's the same thing as before:
%% Data.source(100).flatMap(lambda event: event.fTracks[0].fVertex)

%% ttree.Draw("Sum$(fTracks.fPx)")
%% Data.source(100).map(lambda event: event.fTracks.map(lambda track: track.fPx).sum())

%% ttree.Draw("Sum$(fTracks.fVertex)")
%% Data.source(100).map(lambda event: event.fTracks.flatMap(lambda track: track.fVertex).sum())

%% ttree.Draw("Sum$(fTracks.fVertex[0])")
%% # you might think it's this:
%% # Data.source(100).map(lambda event: event.fTracks.map(lambda track: track.fVertex[0]).sum())
%% # but no, it's actually this:
%% Data.source(100).map(lambda event: event.fTracks[0].fVertex.sum())

%% ttree.Draw("Sum$(fTracks[0].fVertex)")
%% # now you might think it's reversed:
%% # Data.source(100).map(lambda event: event.fTracks.map(lambda track: track.fVertex[0]).sum())
%% # but no, it's the same thing as before:
%% Data.source(100).map(lambda event: event.fTracks[0].fVertex.sum())

%% ### more general stuff

%% # set-like functions
%% print Data.source().map(lambda _: _.fType).distinct()
%% # [u'type0', u'type1', u'type2', u'type3', u'type4']

%% # mix data from different events (intentionally, with "skip" and "zip", not through an indexing error)
%% print Data.zip(Data.source(10).map(lambda _: _.fEvtHdr.fEvtNum),
%%                Data.source(10).skip(1).map(lambda _: _.fEvtHdr.fEvtNum))
%% # [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9)]

%% # classic map-reduce
%% # ... over events
%% print Data.source(10).map(lambda _: (_.fType, _.fTemperature)).reduceByKey(lambda x, y: x + y)
%% # {u'type4': 41.481788635253906, u'type1': 40.54312324523926, u'type0': 41.36261177062988, u'type3': 41.63214874267578, u'type2': 41.47318649291992}
%% # ... over tracks
%% print Data.source(100).flatMap(lambda event: event.fTracks.map(lambda track: (event.fType, track.fPx))).reduceByKey(lambda x, y: x + y)
%% # {u'type4': 71.62951914654695, u'type1': 64.94598009073525, u'type0': 78.63334554358516, u'type3': -70.40691937762313, u'type2': 5.186185833030322}



\end{document}
